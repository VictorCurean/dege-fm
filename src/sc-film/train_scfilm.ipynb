{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mFilmModelEvaluator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FiLMModelEvaluator\n",
      "File \u001B[0;32m~/projects/dege-fm/src/sc-film/models/FilmModelEvaluator.py:12\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataloader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_sciplex\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SciplexDatasetUnseenPerturbations\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msc_film_v2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FiLMResidualModel\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mFiLMModelEvaluator\u001B[39;00m():\n",
      "\u001B[0;31mImportError\u001B[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "from models.FilmModelEvaluator import FiLMModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sciplex train dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571906/571906 [02:11<00:00, 4349.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sciplex test dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571906/571906 [00:59<00:00, 9652.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ...\n",
      "Epoch 1/5\n",
      "Iteration: 10 Loss: 0.22936582565307617\n",
      "Iteration: 20 Loss: 0.07051404565572739\n",
      "Iteration: 30 Loss: 0.03125128522515297\n",
      "Iteration: 40 Loss: 0.01660526916384697\n",
      "Iteration: 50 Loss: 0.011774392798542976\n",
      "Iteration: 60 Loss: 0.008497461676597595\n",
      "Iteration: 70 Loss: 0.006520383059978485\n",
      "Iteration: 80 Loss: 0.00542858149856329\n",
      "Iteration: 90 Loss: 0.004955960903316736\n",
      "Iteration: 100 Loss: 0.004422008525580168\n",
      "Iteration: 110 Loss: 0.003994188271462917\n",
      "Iteration: 120 Loss: 0.0036251430865377188\n",
      "Iteration: 130 Loss: 0.0035679542925208807\n",
      "Iteration: 140 Loss: 0.003531096503138542\n",
      "Iteration: 150 Loss: 0.002954046009108424\n",
      "Iteration: 160 Loss: 0.0033618391025811434\n",
      "Iteration: 170 Loss: 0.0027631449047476053\n",
      "Iteration: 180 Loss: 0.002748751314356923\n",
      "Iteration: 190 Loss: 0.0026824509259313345\n",
      "Iteration: 200 Loss: 0.002254380378872156\n",
      "Iteration: 210 Loss: 0.0019150434527546167\n",
      "Iteration: 220 Loss: 0.0019214319763705134\n",
      "Iteration: 230 Loss: 0.002519014058634639\n",
      "Iteration: 240 Loss: 0.0022938563488423824\n",
      "Iteration: 250 Loss: 0.0020995771046727896\n",
      "Iteration: 260 Loss: 0.0014929811004549265\n",
      "Iteration: 270 Loss: 0.0014547068858519197\n",
      "Iteration: 280 Loss: 0.001353815314359963\n",
      "Iteration: 290 Loss: 0.001327439909800887\n",
      "Iteration: 300 Loss: 0.0015408461913466454\n",
      "Iteration: 310 Loss: 0.0014029082376509905\n",
      "Iteration: 320 Loss: 0.0012884692987427115\n",
      "Iteration: 330 Loss: 0.0011952914064750075\n",
      "Iteration: 340 Loss: 0.0012010610662400723\n",
      "Iteration: 350 Loss: 0.0010423054918646812\n",
      "Iteration: 360 Loss: 0.0010515002068132162\n",
      "Iteration: 370 Loss: 0.0010751193622127175\n",
      "Iteration: 380 Loss: 0.00101481971796602\n",
      "Iteration: 390 Loss: 0.0010519054485484958\n",
      "Iteration: 400 Loss: 0.0008875768980942667\n",
      "Iteration: 410 Loss: 0.0008484795689582825\n",
      "Iteration: 420 Loss: 0.0008782536024227738\n",
      "Iteration: 430 Loss: 0.0009207776747643948\n",
      "Iteration: 440 Loss: 0.0007786122732795775\n",
      "Iteration: 450 Loss: 0.0009139723260886967\n",
      "Iteration: 460 Loss: 0.0007413537241518497\n",
      "Iteration: 470 Loss: 0.0006668207352049649\n",
      "Iteration: 480 Loss: 0.0007245850283652544\n",
      "Iteration: 490 Loss: 0.0006590966950170696\n",
      "Iteration: 500 Loss: 0.0006651605945080519\n",
      "Iteration: 510 Loss: 0.0008296913583762944\n",
      "Iteration: 520 Loss: 0.0006913515971973538\n",
      "Iteration: 530 Loss: 0.000627016241196543\n",
      "Iteration: 540 Loss: 0.0006043015164323151\n",
      "Iteration: 550 Loss: 0.0005938530084677041\n",
      "Iteration: 560 Loss: 0.0005598251591436565\n",
      "Iteration: 570 Loss: 0.0005562339210882783\n",
      "Iteration: 580 Loss: 0.0005025080754421651\n",
      "Iteration: 590 Loss: 0.0005134898237884045\n",
      "Iteration: 600 Loss: 0.0005867735017091036\n",
      "Iteration: 610 Loss: 0.0005321758217178285\n",
      "Iteration: 620 Loss: 0.00048403278924524784\n",
      "Iteration: 630 Loss: 0.0004869509139098227\n",
      "Iteration: 640 Loss: 0.0005060434341430664\n",
      "Iteration: 650 Loss: 0.0004698710690718144\n",
      "Iteration: 660 Loss: 0.00046311598271131516\n",
      "Iteration: 670 Loss: 0.000467581587145105\n",
      "Iteration: 680 Loss: 0.0004256261163391173\n",
      "Iteration: 690 Loss: 0.0004218722751829773\n",
      "Iteration: 700 Loss: 0.00042919357656501234\n",
      "Iteration: 710 Loss: 0.0004463089571800083\n",
      "Iteration: 720 Loss: 0.00042287466931156814\n",
      "Iteration: 730 Loss: 0.0004052801232319325\n",
      "Iteration: 740 Loss: 0.0004039083723910153\n",
      "Iteration: 750 Loss: 0.0004074801690876484\n",
      "Epoch 2/5\n",
      "Iteration: 760 Loss: 0.00039723794907331467\n",
      "Iteration: 770 Loss: 0.00039531290531158447\n",
      "Iteration: 780 Loss: 0.0003984786744695157\n",
      "Iteration: 790 Loss: 0.00037151575088500977\n",
      "Iteration: 800 Loss: 0.00036186547367833555\n",
      "Iteration: 810 Loss: 0.0003661324444692582\n",
      "Iteration: 820 Loss: 0.0003557123418431729\n",
      "Iteration: 830 Loss: 0.00038080281228758395\n",
      "Iteration: 840 Loss: 0.0004198964743409306\n",
      "Iteration: 850 Loss: 0.0003658476343844086\n",
      "Iteration: 860 Loss: 0.00035082927206531167\n",
      "Iteration: 870 Loss: 0.00034287251764908433\n",
      "Iteration: 880 Loss: 0.0003433756937738508\n",
      "Iteration: 890 Loss: 0.00032876787008717656\n",
      "Iteration: 900 Loss: 0.0003291817265562713\n",
      "Iteration: 910 Loss: 0.000335908611305058\n",
      "Iteration: 920 Loss: 0.00032706381171010435\n",
      "Iteration: 930 Loss: 0.000324517983244732\n",
      "Iteration: 940 Loss: 0.00032431117142550647\n",
      "Iteration: 950 Loss: 0.0003219317295588553\n",
      "Iteration: 960 Loss: 0.00031629783916287124\n",
      "Iteration: 970 Loss: 0.0003192343283444643\n",
      "Iteration: 980 Loss: 0.0003121205954812467\n",
      "Iteration: 990 Loss: 0.00030621388577856123\n",
      "Iteration: 1000 Loss: 0.00031494308495894074\n",
      "Iteration: 1010 Loss: 0.0003033248649444431\n",
      "Iteration: 1020 Loss: 0.000300547486403957\n",
      "Iteration: 1030 Loss: 0.0003190829011145979\n",
      "Iteration: 1040 Loss: 0.0003053565160371363\n",
      "Iteration: 1050 Loss: 0.00029506065766327083\n",
      "Iteration: 1060 Loss: 0.0002929145412053913\n",
      "Iteration: 1070 Loss: 0.0002932853240054101\n",
      "Iteration: 1080 Loss: 0.00029924872796982527\n",
      "Iteration: 1090 Loss: 0.0003699037479236722\n",
      "Iteration: 1100 Loss: 0.0003514038980938494\n",
      "Iteration: 1110 Loss: 0.00031271824263967574\n",
      "Iteration: 1120 Loss: 0.0003031018713954836\n",
      "Iteration: 1130 Loss: 0.00029369903495535254\n",
      "Iteration: 1140 Loss: 0.00029814543086104095\n",
      "Iteration: 1150 Loss: 0.00029123653075657785\n",
      "Iteration: 1160 Loss: 0.0002985293394885957\n",
      "Iteration: 1170 Loss: 0.00028858712175861\n",
      "Iteration: 1180 Loss: 0.0002879317326005548\n",
      "Iteration: 1190 Loss: 0.00028760344139300287\n",
      "Iteration: 1200 Loss: 0.00029200888820923865\n",
      "Iteration: 1210 Loss: 0.0002855639031622559\n",
      "Iteration: 1220 Loss: 0.00028030542307533324\n",
      "Iteration: 1230 Loss: 0.00028436380671337247\n",
      "Iteration: 1240 Loss: 0.0002773356100078672\n",
      "Iteration: 1250 Loss: 0.0002828695287462324\n",
      "Iteration: 1260 Loss: 0.0002861554967239499\n",
      "Iteration: 1270 Loss: 0.0002779095957521349\n",
      "Iteration: 1280 Loss: 0.0002848440199159086\n",
      "Iteration: 1290 Loss: 0.00027344291447661817\n",
      "Iteration: 1300 Loss: 0.00027103873435407877\n",
      "Iteration: 1310 Loss: 0.0002783907693810761\n",
      "Iteration: 1320 Loss: 0.0002761712239589542\n",
      "Iteration: 1330 Loss: 0.00027534650871530175\n",
      "Iteration: 1340 Loss: 0.0002749281993601471\n",
      "Iteration: 1350 Loss: 0.0002726874372456223\n",
      "Iteration: 1360 Loss: 0.0002752942673396319\n",
      "Iteration: 1370 Loss: 0.0002806215197779238\n",
      "Iteration: 1380 Loss: 0.0002793308813124895\n",
      "Iteration: 1390 Loss: 0.00027274811873212457\n",
      "Iteration: 1400 Loss: 0.0002729710831772536\n",
      "Iteration: 1410 Loss: 0.0002762021613307297\n",
      "Iteration: 1420 Loss: 0.0002721982600633055\n",
      "Iteration: 1430 Loss: 0.00027448387118056417\n",
      "Iteration: 1440 Loss: 0.00027204080834053457\n",
      "Iteration: 1450 Loss: 0.0002780637878458947\n",
      "Iteration: 1460 Loss: 0.0002818443754222244\n",
      "Iteration: 1470 Loss: 0.0002770879364106804\n",
      "Iteration: 1480 Loss: 0.00027473174850456417\n",
      "Iteration: 1490 Loss: 0.00027548291836865246\n",
      "Iteration: 1500 Loss: 0.0002721546625252813\n",
      "Epoch 3/5\n",
      "Iteration: 1510 Loss: 0.000274626916507259\n",
      "Iteration: 1520 Loss: 0.0002757004403974861\n",
      "Iteration: 1530 Loss: 0.0002751919091679156\n",
      "Iteration: 1540 Loss: 0.00028364089666865766\n",
      "Iteration: 1550 Loss: 0.00027758939540944993\n",
      "Iteration: 1560 Loss: 0.0002730583946686238\n",
      "Iteration: 1570 Loss: 0.0002695129660423845\n",
      "Iteration: 1580 Loss: 0.0002705178631003946\n",
      "Iteration: 1590 Loss: 0.00027206531376577914\n",
      "Iteration: 1600 Loss: 0.0002758337650448084\n",
      "Iteration: 1610 Loss: 0.0002759234921541065\n",
      "Iteration: 1620 Loss: 0.0002717007009778172\n",
      "Iteration: 1630 Loss: 0.0002745100937318057\n",
      "Iteration: 1640 Loss: 0.00027690641582012177\n",
      "Iteration: 1650 Loss: 0.00027223184588365257\n",
      "Iteration: 1660 Loss: 0.00027753872564062476\n",
      "Iteration: 1670 Loss: 0.00027758124633692205\n",
      "Iteration: 1680 Loss: 0.0002806705015245825\n",
      "Iteration: 1690 Loss: 0.0002698717580642551\n",
      "Iteration: 1700 Loss: 0.0002774548775050789\n",
      "Iteration: 1710 Loss: 0.00027569980011321604\n",
      "Iteration: 1720 Loss: 0.0002764437813311815\n",
      "Iteration: 1730 Loss: 0.00027003686409443617\n",
      "Iteration: 1740 Loss: 0.0002759590861387551\n",
      "Iteration: 1750 Loss: 0.0002788117853924632\n",
      "Iteration: 1760 Loss: 0.00026718369917944074\n",
      "Iteration: 1770 Loss: 0.000277487764833495\n",
      "Iteration: 1780 Loss: 0.00027618298190645874\n",
      "Iteration: 1790 Loss: 0.0002725785307120532\n",
      "Iteration: 1800 Loss: 0.0002745422243606299\n",
      "Iteration: 1810 Loss: 0.00028073546127416193\n",
      "Iteration: 1820 Loss: 0.0002797211636789143\n",
      "Iteration: 1830 Loss: 0.0002776907349471003\n",
      "Iteration: 1840 Loss: 0.00027474272064864635\n",
      "Iteration: 1850 Loss: 0.00027333322213962674\n",
      "Iteration: 1860 Loss: 0.000274782971246168\n",
      "Iteration: 1870 Loss: 0.0002696524898055941\n",
      "Iteration: 1880 Loss: 0.0002792385348584503\n",
      "Iteration: 1890 Loss: 0.0002736778405960649\n",
      "Iteration: 1900 Loss: 0.000279660482192412\n",
      "Iteration: 1910 Loss: 0.00027459111879579723\n",
      "Iteration: 1920 Loss: 0.0002748469414655119\n",
      "Iteration: 1930 Loss: 0.0002698646276257932\n",
      "Iteration: 1940 Loss: 0.0002728915715124458\n",
      "Iteration: 1950 Loss: 0.000276388629572466\n",
      "Iteration: 1960 Loss: 0.00027842080453410745\n",
      "Iteration: 1970 Loss: 0.0002706445811782032\n",
      "Iteration: 1980 Loss: 0.0002718853938858956\n",
      "Iteration: 1990 Loss: 0.0002726191596593708\n",
      "Iteration: 2000 Loss: 0.0002783382369671017\n",
      "Iteration: 2010 Loss: 0.0002723474462982267\n",
      "Iteration: 2020 Loss: 0.0002718909818213433\n",
      "Iteration: 2030 Loss: 0.00027996007702313364\n",
      "Iteration: 2040 Loss: 0.00027866396703757346\n",
      "Iteration: 2050 Loss: 0.0002741158823482692\n",
      "Iteration: 2060 Loss: 0.0002801440714392811\n",
      "Iteration: 2070 Loss: 0.0002770069404505193\n",
      "Iteration: 2080 Loss: 0.00027533582760952413\n",
      "Iteration: 2090 Loss: 0.00028100196504965425\n",
      "Iteration: 2100 Loss: 0.00027954281540587544\n",
      "Iteration: 2110 Loss: 0.00027817822410725057\n",
      "Iteration: 2120 Loss: 0.0002736095048021525\n",
      "Iteration: 2130 Loss: 0.00027671997668221593\n",
      "Iteration: 2140 Loss: 0.00026770957629196346\n",
      "Iteration: 2150 Loss: 0.0002738110488280654\n",
      "Iteration: 2160 Loss: 0.0002709183027036488\n",
      "Iteration: 2170 Loss: 0.00027596676954999566\n",
      "Iteration: 2180 Loss: 0.0002731765853241086\n",
      "Iteration: 2190 Loss: 0.0002871645556297153\n",
      "Iteration: 2200 Loss: 0.0002675848954822868\n",
      "Iteration: 2210 Loss: 0.0002714380098041147\n",
      "Iteration: 2220 Loss: 0.00027925209724344313\n",
      "Iteration: 2230 Loss: 0.00027158838929608464\n",
      "Iteration: 2240 Loss: 0.00027868166216649115\n",
      "Iteration: 2250 Loss: 0.0002798517234623432\n",
      "Epoch 4/5\n",
      "Iteration: 2260 Loss: 0.0002729018742684275\n",
      "Iteration: 2270 Loss: 0.0002777182962745428\n",
      "Iteration: 2280 Loss: 0.00027524185134097934\n",
      "Iteration: 2290 Loss: 0.00027281473740004003\n",
      "Iteration: 2300 Loss: 0.0002663803461473435\n",
      "Iteration: 2310 Loss: 0.0002707711246330291\n",
      "Iteration: 2320 Loss: 0.0002763960510492325\n",
      "Iteration: 2330 Loss: 0.00027024498558603227\n",
      "Iteration: 2340 Loss: 0.00027310449513606727\n",
      "Iteration: 2350 Loss: 0.00027840034454129636\n",
      "Iteration: 2360 Loss: 0.0002758245973382145\n",
      "Iteration: 2370 Loss: 0.0002738357870839536\n",
      "Iteration: 2380 Loss: 0.0002738033945206553\n",
      "Iteration: 2390 Loss: 0.00027700859936885536\n",
      "Iteration: 2400 Loss: 0.0002829186269082129\n",
      "Iteration: 2410 Loss: 0.0002747573598753661\n",
      "Iteration: 2420 Loss: 0.0002797419729176909\n",
      "Iteration: 2430 Loss: 0.0002726603706832975\n",
      "Iteration: 2440 Loss: 0.0002820898953359574\n",
      "Iteration: 2450 Loss: 0.0002826678683049977\n",
      "Iteration: 2460 Loss: 0.00027264279196970165\n",
      "Iteration: 2470 Loss: 0.0002750369894783944\n",
      "Iteration: 2480 Loss: 0.00027868259348906577\n",
      "Iteration: 2490 Loss: 0.0002706359082367271\n",
      "Iteration: 2500 Loss: 0.0002703556092455983\n",
      "Iteration: 2510 Loss: 0.00026751781115308404\n",
      "Iteration: 2520 Loss: 0.00027304794639348984\n",
      "Iteration: 2530 Loss: 0.0002781970542855561\n",
      "Iteration: 2540 Loss: 0.00027593562845140696\n",
      "Iteration: 2550 Loss: 0.0002744391094893217\n",
      "Iteration: 2560 Loss: 0.00028094719164073467\n",
      "Iteration: 2570 Loss: 0.0002763661032076925\n",
      "Iteration: 2580 Loss: 0.0002735174202825874\n",
      "Iteration: 2590 Loss: 0.0002757407783064991\n",
      "Iteration: 2600 Loss: 0.0002796008193399757\n",
      "Iteration: 2610 Loss: 0.00026996401720680296\n",
      "Iteration: 2620 Loss: 0.0002692617126740515\n",
      "Iteration: 2630 Loss: 0.0002751935098785907\n",
      "Iteration: 2640 Loss: 0.000271125027211383\n",
      "Iteration: 2650 Loss: 0.00027437182143330574\n",
      "Iteration: 2660 Loss: 0.00027546091587282717\n",
      "Iteration: 2670 Loss: 0.0002702258643694222\n",
      "Iteration: 2680 Loss: 0.0002768200356513262\n",
      "Iteration: 2690 Loss: 0.00027647591196000576\n",
      "Iteration: 2700 Loss: 0.00027684864471666515\n",
      "Iteration: 2710 Loss: 0.00026720776804722846\n",
      "Iteration: 2720 Loss: 0.00027248705737292767\n",
      "Iteration: 2730 Loss: 0.000269937765551731\n",
      "Iteration: 2740 Loss: 0.0002776810433715582\n",
      "Iteration: 2750 Loss: 0.0002753622829914093\n",
      "Iteration: 2760 Loss: 0.0002759680792223662\n",
      "Iteration: 2770 Loss: 0.0002843978290911764\n",
      "Iteration: 2780 Loss: 0.0002782746159937233\n",
      "Iteration: 2790 Loss: 0.0002727738756220788\n",
      "Iteration: 2800 Loss: 0.0002793535531964153\n",
      "Iteration: 2810 Loss: 0.000277356943115592\n",
      "Iteration: 2820 Loss: 0.00028433019178919494\n",
      "Iteration: 2830 Loss: 0.0002740818599704653\n",
      "Iteration: 2840 Loss: 0.0002819976944010705\n",
      "Iteration: 2850 Loss: 0.0002715794544201344\n",
      "Iteration: 2860 Loss: 0.00027540960581973195\n",
      "Iteration: 2870 Loss: 0.00028682785341516137\n",
      "Iteration: 2880 Loss: 0.00027402545674704015\n",
      "Iteration: 2890 Loss: 0.0002791193255688995\n",
      "Iteration: 2900 Loss: 0.0002710625121835619\n",
      "Iteration: 2910 Loss: 0.00027611872064881027\n",
      "Iteration: 2920 Loss: 0.000274479592917487\n",
      "Iteration: 2930 Loss: 0.00027971024974249303\n",
      "Iteration: 2940 Loss: 0.00027923911693505943\n",
      "Iteration: 2950 Loss: 0.0002705671649891883\n",
      "Iteration: 2960 Loss: 0.00027149092056788504\n",
      "Iteration: 2970 Loss: 0.00027983722975477576\n",
      "Iteration: 2980 Loss: 0.0002746127138379961\n",
      "Iteration: 2990 Loss: 0.0002762147632893175\n",
      "Iteration: 3000 Loss: 0.00027741550002247095\n",
      "Epoch 5/5\n",
      "Iteration: 3010 Loss: 0.00028214705525897443\n",
      "Iteration: 3020 Loss: 0.0002791201404761523\n",
      "Iteration: 3030 Loss: 0.0002768975682556629\n",
      "Iteration: 3040 Loss: 0.00028439104789867997\n",
      "Iteration: 3050 Loss: 0.00026805303059518337\n",
      "Iteration: 3060 Loss: 0.00027398508973419666\n",
      "Iteration: 3070 Loss: 0.00026873391470871866\n",
      "Iteration: 3080 Loss: 0.0002792719751596451\n",
      "Iteration: 3090 Loss: 0.00026680491282604635\n",
      "Iteration: 3100 Loss: 0.0002831082383636385\n",
      "Iteration: 3110 Loss: 0.0002747754624579102\n",
      "Iteration: 3120 Loss: 0.0002762025105766952\n",
      "Iteration: 3130 Loss: 0.0002719443873502314\n",
      "Iteration: 3140 Loss: 0.0002739007759373635\n",
      "Iteration: 3150 Loss: 0.0002726139791775495\n",
      "Iteration: 3160 Loss: 0.000280976586509496\n",
      "Iteration: 3170 Loss: 0.0002732554858084768\n",
      "Iteration: 3180 Loss: 0.00027499935822561383\n",
      "Iteration: 3190 Loss: 0.00027868730830959976\n",
      "Iteration: 3200 Loss: 0.0002753496228251606\n",
      "Iteration: 3210 Loss: 0.000280753243714571\n",
      "Iteration: 3220 Loss: 0.00027404638240113854\n",
      "Iteration: 3230 Loss: 0.00027647780370898545\n",
      "Iteration: 3240 Loss: 0.0002771395375020802\n",
      "Iteration: 3250 Loss: 0.00027161926846019924\n",
      "Iteration: 3260 Loss: 0.00027338857762515545\n",
      "Iteration: 3270 Loss: 0.0002704513899516314\n",
      "Iteration: 3280 Loss: 0.00028025161009281874\n",
      "Iteration: 3290 Loss: 0.0002740476920735091\n",
      "Iteration: 3300 Loss: 0.0002723966899793595\n",
      "Iteration: 3310 Loss: 0.0002723893558140844\n",
      "Iteration: 3320 Loss: 0.0002773150918073952\n",
      "Iteration: 3330 Loss: 0.0002796816697809845\n",
      "Iteration: 3340 Loss: 0.00027296473854221404\n",
      "Iteration: 3350 Loss: 0.0002697991149034351\n",
      "Iteration: 3360 Loss: 0.0002813735627569258\n",
      "Iteration: 3370 Loss: 0.00027129208319820464\n",
      "Iteration: 3380 Loss: 0.000275087368208915\n",
      "Iteration: 3390 Loss: 0.0002768932608887553\n",
      "Iteration: 3400 Loss: 0.00027628408861346543\n",
      "Iteration: 3410 Loss: 0.0002798263158183545\n",
      "Iteration: 3420 Loss: 0.00027529156068339944\n",
      "Iteration: 3430 Loss: 0.0002705234510358423\n",
      "Iteration: 3440 Loss: 0.00026791405980475247\n",
      "Iteration: 3450 Loss: 0.00027427409077063203\n",
      "Iteration: 3460 Loss: 0.00027500474243424833\n",
      "Iteration: 3470 Loss: 0.00027305580442771316\n",
      "Iteration: 3480 Loss: 0.00027991083334200084\n",
      "Iteration: 3490 Loss: 0.000277727929642424\n",
      "Iteration: 3500 Loss: 0.0002784381795208901\n",
      "Iteration: 3510 Loss: 0.00027673106524161994\n",
      "Iteration: 3520 Loss: 0.00027810496976599097\n",
      "Iteration: 3530 Loss: 0.00027727801352739334\n",
      "Iteration: 3540 Loss: 0.00028292470960877836\n",
      "Iteration: 3550 Loss: 0.0002808761491905898\n",
      "Iteration: 3560 Loss: 0.00027816975489258766\n",
      "Iteration: 3570 Loss: 0.00027787135331891477\n",
      "Iteration: 3580 Loss: 0.0002743230143096298\n",
      "Iteration: 3590 Loss: 0.0002713751164264977\n",
      "Iteration: 3600 Loss: 0.00027390645118430257\n",
      "Iteration: 3610 Loss: 0.00027872819919139147\n",
      "Iteration: 3620 Loss: 0.00027866006712429225\n",
      "Iteration: 3630 Loss: 0.0002674381248652935\n",
      "Iteration: 3640 Loss: 0.00027509007486514747\n",
      "Iteration: 3650 Loss: 0.0002791548613458872\n",
      "Iteration: 3660 Loss: 0.00027860290720127523\n",
      "Iteration: 3670 Loss: 0.00028246143483556807\n",
      "Iteration: 3680 Loss: 0.0002760599018074572\n",
      "Iteration: 3690 Loss: 0.0002796863846015185\n",
      "Iteration: 3700 Loss: 0.00027093637618236244\n",
      "Iteration: 3710 Loss: 0.0002805423573590815\n",
      "Iteration: 3720 Loss: 0.0002753459266386926\n",
      "Iteration: 3730 Loss: 0.0002810171281453222\n",
      "Iteration: 3740 Loss: 0.00027698121266439557\n",
      "Iteration: 3750 Loss: 0.00027604607748799026\n",
      "Iteration: 3760 Loss: 0.0002829265722539276\n",
      "Training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 270/270 [00:04<00:00, 61.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing completed. Results stored in 'self.test_results'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval = FiLMModelEvaluator(\"../../../config/FiLM.yaml\")\n",
    "eval.train()\n",
    "eval.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 27.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 25.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 27.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 74.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 59.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 74.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PCP: {'A549': 0.4147727272727273, 'K562': 0.44886363636363635, 'MCF7': 0.30113636363636365}\n",
      "Test PR perturbed: {'A549': np.float64(0.6272727272727273), 'K562': np.float64(0.4272727272727272), 'MCF7': np.float64(0.6000000000000001)}\n",
      "Test PR predicted: {'A549': np.float64(-0.02272727272727272), 'K562': np.float64(-0.022727272727272742), 'MCF7': np.float64(-0.06818181818181818)}\n",
      "Test Loss: {'A549': np.float64(0.5795402396678364), 'K562': np.float64(0.6466294417492877), 'MCF7': np.float64(0.5585339945218232)}\n",
      "Null Model Loss: {'A549': np.float64(0.7637983937979376), 'K562': np.float64(0.8508015303683408), 'MCF7': np.float64(0.73789172063709)}\n"
     ]
    }
   ],
   "source": [
    "eval.get_stats(euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
